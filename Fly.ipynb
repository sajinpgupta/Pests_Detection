{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f45a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install opencv-python\n",
    "# !pip install ultralytics opencv-python pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21566da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Using cached weights: yolov8s.pt\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# pip install ultralytics opencv-python pillow\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Download YOLO weights if missing\n",
    "# ----------------------------\n",
    "def download_weights(weights_name=\"yolov8n.pt\"):\n",
    "    \"\"\"\n",
    "    Download YOLO pretrained weights from Ultralytics if not available locally.\n",
    "    Options: yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\n",
    "    \"\"\"\n",
    "    if not os.path.exists(weights_name):\n",
    "    # if 1==1:\n",
    "        import requests\n",
    "        url = f\"https://github.com/ultralytics/assets/releases/download/v0.0.0/{weights_name}\"\n",
    "        #url = \"https://github.com/therajsekharsaha/pestdetection/tree/main/pestdetection/yolov8n.pt\"\n",
    "        print(f\"Downloading {weights_name}...\")\n",
    "        r = requests.get(url)\n",
    "        with open('Model/'+weights_name, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        print(f\"✅ Downloaded {weights_name}\")\n",
    "    else:\n",
    "        print(f\"⚡ Using cached weights: {weights_name}\")\n",
    "\n",
    "# Call function to ensure weights are present\n",
    "download_weights(\"yolov8s.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e594521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG-20250817-WA0081.jpg', 'IMG-20250817-WA0082.jpg', 'IMG-20250817-WA0083.jpg', 'IMG-20250817-WA0084.jpg', 'IMG-20250817-WA0085.jpg']\n",
      "processing image IMG-20250817-WA0081.jpg\n",
      "Reshaping IMG-20250817-WA0081.jpg from (1600, 900, 3) to (1280, 720)\n",
      "/Users/sajin/ML/Projects/Agri-1/Fly/Images/processed/preprocessed_IMG-20250817-WA0081.jpg\n",
      "\n",
      "0: 384x672 8 fruit flys, 57.5ms\n",
      "Speed: 35.8ms preprocess, 57.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 672)\n",
      "[(702, 313, 126, 38), (333, 253, 66, 44), (915, 645, 108, 37), (370, 329, 78, 39), (43, 621, 110, 53), (551, 543, 208, 75), (956, 648, 80, 34), (386, 329, 75, 39)]\n",
      "CLIP:  {'bbox': (702, 313, 126, 38), 'label': 'fungus gnat', 'confidence': 0.7956477403640747, 'topk': [('fungus gnat', 0.7956477403640747)]}\n",
      "CLIP:  {'bbox': (333, 253, 66, 44), 'label': 'fungus gnat', 'confidence': 0.5973458886146545, 'topk': [('fungus gnat', 0.5973458886146545)]}\n",
      "CLIP:  {'bbox': (915, 645, 108, 37), 'label': 'fungus gnat', 'confidence': 0.5749718546867371, 'topk': [('fungus gnat', 0.5749718546867371)]}\n",
      "CLIP:  {'bbox': (370, 329, 78, 39), 'label': 'leafhopper', 'confidence': 0.5130388140678406, 'topk': [('leafhopper', 0.5130388140678406)]}\n",
      "CLIP:  {'bbox': (43, 621, 110, 53), 'label': 'leafhopper', 'confidence': 0.7844305038452148, 'topk': [('leafhopper', 0.7844305038452148)]}\n",
      "CLIP:  {'bbox': (551, 543, 208, 75), 'label': 'leafhopper', 'confidence': 0.7180383801460266, 'topk': [('leafhopper', 0.7180383801460266)]}\n",
      "CLIP:  {'bbox': (956, 648, 80, 34), 'label': 'fungus gnat', 'confidence': 0.5493913888931274, 'topk': [('fungus gnat', 0.5493913888931274)]}\n",
      "CLIP:  {'bbox': (386, 329, 75, 39), 'label': 'fungus gnat', 'confidence': 0.445865273475647, 'topk': [('fungus gnat', 0.445865273475647)]}\n",
      "✅ Detection complete! Results saved det_IMG-20250817-WA0081.jpg\n",
      "processing image IMG-20250817-WA0082.jpg\n",
      "Reshaping IMG-20250817-WA0082.jpg from (1600, 900, 3) to (1280, 720)\n",
      "/Users/sajin/ML/Projects/Agri-1/Fly/Images/processed/preprocessed_IMG-20250817-WA0082.jpg\n",
      "\n",
      "0: 384x672 10 fruit flys, 65.6ms\n",
      "Speed: 3.4ms preprocess, 65.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 672)\n",
      "[(411, 461, 157, 71), (517, 547, 158, 81), (374, 322, 119, 40), (109, 275, 95, 46), (889, 619, 84, 50), (1060, 510, 81, 53), (1120, 268, 97, 36), (99, 274, 90, 43), (897, 336, 171, 45), (369, 323, 141, 48)]\n",
      "CLIP:  {'bbox': (411, 461, 157, 71), 'label': 'fungus gnat', 'confidence': 0.4656490385532379, 'topk': [('fungus gnat', 0.4656490385532379)]}\n",
      "CLIP:  {'bbox': (517, 547, 158, 81), 'label': 'fungus gnat', 'confidence': 0.6186625957489014, 'topk': [('fungus gnat', 0.6186625957489014)]}\n",
      "CLIP:  {'bbox': (374, 322, 119, 40), 'label': 'fungus gnat', 'confidence': 0.5377863645553589, 'topk': [('fungus gnat', 0.5377863645553589)]}\n",
      "CLIP:  {'bbox': (109, 275, 95, 46), 'label': 'fungus gnat', 'confidence': 0.6439415812492371, 'topk': [('fungus gnat', 0.6439415812492371)]}\n",
      "CLIP:  {'bbox': (889, 619, 84, 50), 'label': 'fungus gnat', 'confidence': 0.43105703592300415, 'topk': [('fungus gnat', 0.43105703592300415)]}\n",
      "CLIP:  {'bbox': (1060, 510, 81, 53), 'label': 'leafhopper', 'confidence': 0.5544992089271545, 'topk': [('leafhopper', 0.5544992089271545)]}\n",
      "CLIP:  {'bbox': (1120, 268, 97, 36), 'label': 'leafhopper', 'confidence': 0.3787650465965271, 'topk': [('leafhopper', 0.3787650465965271)]}\n",
      "CLIP:  {'bbox': (99, 274, 90, 43), 'label': 'fungus gnat', 'confidence': 0.719639778137207, 'topk': [('fungus gnat', 0.719639778137207)]}\n",
      "CLIP:  {'bbox': (897, 336, 171, 45), 'label': 'fungus gnat', 'confidence': 0.5009251832962036, 'topk': [('fungus gnat', 0.5009251832962036)]}\n",
      "CLIP:  {'bbox': (369, 323, 141, 48), 'label': 'fungus gnat', 'confidence': 0.4558502435684204, 'topk': [('fungus gnat', 0.4558502435684204)]}\n",
      "✅ Detection complete! Results saved det_IMG-20250817-WA0082.jpg\n",
      "processing image IMG-20250817-WA0083.jpg\n",
      "Reshaping IMG-20250817-WA0083.jpg from (1600, 900, 3) to (1280, 720)\n",
      "/Users/sajin/ML/Projects/Agri-1/Fly/Images/processed/preprocessed_IMG-20250817-WA0083.jpg\n",
      "\n",
      "0: 384x672 23 fruit flys, 66.2ms\n",
      "Speed: 3.3ms preprocess, 66.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 672)\n",
      "[(242, 91, 151, 62), (990, 225, 103, 43), (56, 117, 121, 76), (120, 0, 155, 39), (279, 190, 103, 40), (402, 323, 103, 39), (840, 4, 191, 69), (231, 17, 127, 55), (482, 317, 94, 45), (140, 639, 100, 49), (36, 41, 108, 35), (397, 506, 128, 48), (885, 314, 69, 33), (0, 294, 44, 42), (979, 226, 125, 50), (727, 274, 79, 35), (914, 264, 57, 33), (1093, 440, 81, 36), (770, 493, 84, 36), (1124, 292, 61, 34), (846, 531, 74, 37), (873, 532, 99, 36), (856, 313, 92, 37)]\n",
      "CLIP:  {'bbox': (242, 91, 151, 62), 'label': 'fungus gnat', 'confidence': 0.5446391701698303, 'topk': [('fungus gnat', 0.5446391701698303)]}\n",
      "CLIP:  {'bbox': (990, 225, 103, 43), 'label': 'leafhopper', 'confidence': 0.4366484582424164, 'topk': [('leafhopper', 0.4366484582424164)]}\n",
      "CLIP:  {'bbox': (56, 117, 121, 76), 'label': 'fungus gnat', 'confidence': 0.601020872592926, 'topk': [('fungus gnat', 0.601020872592926)]}\n",
      "CLIP:  {'bbox': (120, 0, 155, 39), 'label': 'leafhopper', 'confidence': 0.41650351881980896, 'topk': [('leafhopper', 0.41650351881980896)]}\n",
      "CLIP:  {'bbox': (279, 190, 103, 40), 'label': 'fungus gnat', 'confidence': 0.5860487818717957, 'topk': [('fungus gnat', 0.5860487818717957)]}\n",
      "CLIP:  {'bbox': (402, 323, 103, 39), 'label': 'fungus gnat', 'confidence': 0.6289846301078796, 'topk': [('fungus gnat', 0.6289846301078796)]}\n",
      "CLIP:  {'bbox': (840, 4, 191, 69), 'label': 'leafhopper', 'confidence': 0.4879530668258667, 'topk': [('leafhopper', 0.4879530668258667)]}\n",
      "CLIP:  {'bbox': (231, 17, 127, 55), 'label': 'fungus gnat', 'confidence': 0.6093639731407166, 'topk': [('fungus gnat', 0.6093639731407166)]}\n",
      "CLIP:  {'bbox': (482, 317, 94, 45), 'label': 'fungus gnat', 'confidence': 0.48480623960494995, 'topk': [('fungus gnat', 0.48480623960494995)]}\n",
      "CLIP:  {'bbox': (140, 639, 100, 49), 'label': 'leafhopper', 'confidence': 0.3915022611618042, 'topk': [('leafhopper', 0.3915022611618042)]}\n",
      "CLIP:  {'bbox': (36, 41, 108, 35), 'label': 'leafhopper', 'confidence': 0.4819176197052002, 'topk': [('leafhopper', 0.4819176197052002)]}\n",
      "CLIP:  {'bbox': (397, 506, 128, 48), 'label': 'fungus gnat', 'confidence': 0.6876157522201538, 'topk': [('fungus gnat', 0.6876157522201538)]}\n",
      "CLIP:  {'bbox': (885, 314, 69, 33), 'label': 'fungus gnat', 'confidence': 0.35531333088874817, 'topk': [('fungus gnat', 0.35531333088874817)]}\n",
      "CLIP:  {'bbox': (0, 294, 44, 42), 'label': 'fungus gnat', 'confidence': 0.3779166340827942, 'topk': [('fungus gnat', 0.3779166340827942)]}\n",
      "CLIP:  {'bbox': (979, 226, 125, 50), 'label': 'leafhopper', 'confidence': 0.485750287771225, 'topk': [('leafhopper', 0.485750287771225)]}\n",
      "CLIP:  {'bbox': (727, 274, 79, 35), 'label': 'fungus gnat', 'confidence': 0.4892084002494812, 'topk': [('fungus gnat', 0.4892084002494812)]}\n",
      "CLIP:  {'bbox': (914, 264, 57, 33), 'label': 'fungus gnat', 'confidence': 0.3699568808078766, 'topk': [('fungus gnat', 0.3699568808078766)]}\n",
      "CLIP:  {'bbox': (1093, 440, 81, 36), 'label': 'unknown', 'confidence': 0.31773707270622253, 'topk': [('whitefly', 0.31773707270622253)]}\n",
      "CLIP:  {'bbox': (770, 493, 84, 36), 'label': 'fungus gnat', 'confidence': 0.5643281936645508, 'topk': [('fungus gnat', 0.5643281936645508)]}\n",
      "CLIP:  {'bbox': (1124, 292, 61, 34), 'label': 'fungus gnat', 'confidence': 0.5442500710487366, 'topk': [('fungus gnat', 0.5442500710487366)]}\n",
      "CLIP:  {'bbox': (846, 531, 74, 37), 'label': 'fungus gnat', 'confidence': 0.4377598762512207, 'topk': [('fungus gnat', 0.4377598762512207)]}\n",
      "CLIP:  {'bbox': (873, 532, 99, 36), 'label': 'fungus gnat', 'confidence': 0.5734372138977051, 'topk': [('fungus gnat', 0.5734372138977051)]}\n",
      "CLIP:  {'bbox': (856, 313, 92, 37), 'label': 'fungus gnat', 'confidence': 0.44228923320770264, 'topk': [('fungus gnat', 0.44228923320770264)]}\n",
      "✅ Detection complete! Results saved det_IMG-20250817-WA0083.jpg\n",
      "processing image IMG-20250817-WA0084.jpg\n",
      "Reshaping IMG-20250817-WA0084.jpg from (1600, 900, 3) to (1280, 720)\n",
      "/Users/sajin/ML/Projects/Agri-1/Fly/Images/processed/preprocessed_IMG-20250817-WA0084.jpg\n",
      "\n",
      "0: 384x672 6 fruit flys, 64.1ms\n",
      "Speed: 4.1ms preprocess, 64.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 672)\n",
      "[(500, 493, 187, 84), (945, 618, 125, 43), (257, 576, 159, 61), (63, 576, 203, 72), (60, 585, 186, 56), (485, 322, 91, 49)]\n",
      "CLIP:  {'bbox': (500, 493, 187, 84), 'label': 'beetle', 'confidence': 0.35070157051086426, 'topk': [('beetle', 0.35070157051086426)]}\n",
      "CLIP:  {'bbox': (945, 618, 125, 43), 'label': 'leafhopper', 'confidence': 0.4029916524887085, 'topk': [('leafhopper', 0.4029916524887085)]}\n",
      "CLIP:  {'bbox': (257, 576, 159, 61), 'label': 'leafhopper', 'confidence': 0.6434983611106873, 'topk': [('leafhopper', 0.6434983611106873)]}\n",
      "CLIP:  {'bbox': (63, 576, 203, 72), 'label': 'fungus gnat', 'confidence': 0.44642898440361023, 'topk': [('fungus gnat', 0.44642898440361023)]}\n",
      "CLIP:  {'bbox': (60, 585, 186, 56), 'label': 'fungus gnat', 'confidence': 0.4250166416168213, 'topk': [('fungus gnat', 0.4250166416168213)]}\n",
      "CLIP:  {'bbox': (485, 322, 91, 49), 'label': 'leafhopper', 'confidence': 0.44136157631874084, 'topk': [('leafhopper', 0.44136157631874084)]}\n",
      "✅ Detection complete! Results saved det_IMG-20250817-WA0084.jpg\n",
      "processing image IMG-20250817-WA0085.jpg\n",
      "Reshaping IMG-20250817-WA0085.jpg from (1600, 900, 3) to (1280, 720)\n",
      "/Users/sajin/ML/Projects/Agri-1/Fly/Images/processed/preprocessed_IMG-20250817-WA0085.jpg\n",
      "\n",
      "0: 384x672 23 fruit flys, 72.0ms\n",
      "Speed: 3.5ms preprocess, 72.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 672)\n",
      "[(908, 659, 73, 37), (0, 644, 57, 31), (926, 661, 68, 34), (238, 293, 112, 47), (4, 641, 73, 34), (932, 415, 118, 46), (497, 674, 67, 40), (914, 0, 169, 83), (1037, 264, 99, 29), (81, 627, 73, 37), (105, 564, 64, 39), (831, 583, 70, 39), (968, 609, 74, 49), (708, 285, 129, 44), (686, 283, 153, 54), (486, 470, 70, 42), (626, 537, 107, 45), (652, 335, 81, 41), (61, 626, 75, 37), (638, 331, 87, 43), (212, 482, 57, 35), (624, 332, 77, 42), (1009, 263, 138, 36)]\n",
      "CLIP:  {'bbox': (908, 659, 73, 37), 'label': 'fungus gnat', 'confidence': 0.4748978018760681, 'topk': [('fungus gnat', 0.4748978018760681)]}\n",
      "CLIP:  {'bbox': (0, 644, 57, 31), 'label': 'unknown', 'confidence': 0.3430230915546417, 'topk': [('leafhopper', 0.3430230915546417)]}\n",
      "CLIP:  {'bbox': (926, 661, 68, 34), 'label': 'fungus gnat', 'confidence': 0.3743501901626587, 'topk': [('fungus gnat', 0.3743501901626587)]}\n",
      "CLIP:  {'bbox': (238, 293, 112, 47), 'label': 'fungus gnat', 'confidence': 0.6228644847869873, 'topk': [('fungus gnat', 0.6228644847869873)]}\n",
      "CLIP:  {'bbox': (4, 641, 73, 34), 'label': 'fungus gnat', 'confidence': 0.37441813945770264, 'topk': [('fungus gnat', 0.37441813945770264)]}\n",
      "CLIP:  {'bbox': (932, 415, 118, 46), 'label': 'leafhopper', 'confidence': 0.4949033558368683, 'topk': [('leafhopper', 0.4949033558368683)]}\n",
      "CLIP:  {'bbox': (497, 674, 67, 40), 'label': 'leafhopper', 'confidence': 0.5202808976173401, 'topk': [('leafhopper', 0.5202808976173401)]}\n",
      "CLIP:  {'bbox': (914, 0, 169, 83), 'label': 'unknown', 'confidence': 0.3129361569881439, 'topk': [('leafhopper', 0.3129361569881439)]}\n",
      "CLIP:  {'bbox': (1037, 264, 99, 29), 'label': 'leafhopper', 'confidence': 0.5352690815925598, 'topk': [('leafhopper', 0.5352690815925598)]}\n",
      "CLIP:  {'bbox': (81, 627, 73, 37), 'label': 'fungus gnat', 'confidence': 0.5436603426933289, 'topk': [('fungus gnat', 0.5436603426933289)]}\n",
      "CLIP:  {'bbox': (105, 564, 64, 39), 'label': 'fungus gnat', 'confidence': 0.560688853263855, 'topk': [('fungus gnat', 0.560688853263855)]}\n",
      "CLIP:  {'bbox': (831, 583, 70, 39), 'label': 'fungus gnat', 'confidence': 0.6332698464393616, 'topk': [('fungus gnat', 0.6332698464393616)]}\n",
      "CLIP:  {'bbox': (968, 609, 74, 49), 'label': 'fungus gnat', 'confidence': 0.45086154341697693, 'topk': [('fungus gnat', 0.45086154341697693)]}\n",
      "CLIP:  {'bbox': (708, 285, 129, 44), 'label': 'fungus gnat', 'confidence': 0.5432628989219666, 'topk': [('fungus gnat', 0.5432628989219666)]}\n",
      "CLIP:  {'bbox': (686, 283, 153, 54), 'label': 'fungus gnat', 'confidence': 0.6823380589485168, 'topk': [('fungus gnat', 0.6823380589485168)]}\n",
      "CLIP:  {'bbox': (486, 470, 70, 42), 'label': 'fungus gnat', 'confidence': 0.5762996673583984, 'topk': [('fungus gnat', 0.5762996673583984)]}\n",
      "CLIP:  {'bbox': (626, 537, 107, 45), 'label': 'fungus gnat', 'confidence': 0.6839244365692139, 'topk': [('fungus gnat', 0.6839244365692139)]}\n",
      "CLIP:  {'bbox': (652, 335, 81, 41), 'label': 'leafhopper', 'confidence': 0.5120500326156616, 'topk': [('leafhopper', 0.5120500326156616)]}\n",
      "CLIP:  {'bbox': (61, 626, 75, 37), 'label': 'fungus gnat', 'confidence': 0.5870296955108643, 'topk': [('fungus gnat', 0.5870296955108643)]}\n",
      "CLIP:  {'bbox': (638, 331, 87, 43), 'label': 'fungus gnat', 'confidence': 0.3766317069530487, 'topk': [('fungus gnat', 0.3766317069530487)]}\n",
      "CLIP:  {'bbox': (212, 482, 57, 35), 'label': 'fungus gnat', 'confidence': 0.47242996096611023, 'topk': [('fungus gnat', 0.47242996096611023)]}\n",
      "CLIP:  {'bbox': (624, 332, 77, 42), 'label': 'fungus gnat', 'confidence': 0.7226139307022095, 'topk': [('fungus gnat', 0.7226139307022095)]}\n",
      "CLIP:  {'bbox': (1009, 263, 138, 36), 'label': 'leafhopper', 'confidence': 0.5567116141319275, 'topk': [('leafhopper', 0.5567116141319275)]}\n",
      "✅ Detection complete! Results saved det_IMG-20250817-WA0085.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 2. Load image & preprocessing\n",
    "# ----------------------------\n",
    "from PIL import Image\n",
    "image_path = \"/Users/sajin/ML/Projects/Agri-1/Fly/Images/\"  # replace with your trap image\n",
    "processed_path = \"/Users/sajin/ML/Projects/Agri-1/Fly/Images/processed/\"\n",
    "images_list = os.listdir(image_path)\n",
    "images_list = [x for x in images_list if x.find('det') ==-1 & x.find('preprocessed_') == -1 & x.find('processed') == -1 ]\n",
    "print(images_list)\n",
    "\n",
    "\n",
    "for each_image in images_list:\n",
    "    img = cv2.imread(image_path+ each_image)\n",
    "    print(f\"processing image {each_image}\")\n",
    "\n",
    "    # Resize for consistency\n",
    "    print(f\"Reshaping {each_image} from {img.shape} to (1280, 720)\")\n",
    "    img = cv2.resize(img, (1280, 720))\n",
    "\n",
    "    # Convert BGR → HSV to normalize yellow background\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Mask yellow background\n",
    "    lower_yellow = np.array([20, 80, 80])\n",
    "    upper_yellow = np.array([40, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    # Invert mask → insects remain\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    refined = cv2.bitwise_and(img, img, mask=mask_inv)\n",
    "\n",
    "    # Contrast enhancement with CLAHE\n",
    "    gray = cv2.cvtColor(refined, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    gray_eq = clahe.apply(gray)\n",
    "    refined = cv2.cvtColor(gray_eq, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    file = processed_path+\"preprocessed_\"+each_image\n",
    "    print(file)\n",
    "    if not os.path.exists(file):\n",
    "       cv2.imwrite(file, refined)\n",
    "\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3. Load YOLOv8 Model\n",
    "    # ----------------------------\n",
    "    yolo_model = YOLO(\"Model/best.pt\")  # lightweight model for testing\n",
    "   #  yolo_model = YOLO(\"yolov8s.pt\")  # lightweight model for testing\n",
    "    # You can swap for yolov8s.pt or yolov8m.pt for more accuracy\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4. Run Detection\n",
    "    # ----------------------------\n",
    "   #  results = model.predict(refined, imgsz=640, conf=0.25)\n",
    "    results = yolo_model.predict(img, conf=0.30 )\n",
    "    # ----------------------------\n",
    "    # 5. Draw bounding boxes & labels\n",
    "    # ----------------------------\n",
    "    #print('R :',results[0].boxes)\n",
    "    boxes = results[0].boxes\n",
    "    xyxy = boxes.xyxy\n",
    "    xywh = boxes.xywh\n",
    "    conf = boxes.conf\n",
    "    cls  = boxes.cls\n",
    "\n",
    "    bboxes = []\n",
    "    for xyxy_box in boxes.xyxy.cpu().numpy():\n",
    "       x1, y1, x2, y2 = xyxy_box\n",
    "       w, h = x2 - x1, y2 - y1\n",
    "       bboxes.append((int(x1), int(y1), int(w), int(h)))\n",
    "\n",
    "    print(bboxes)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(img_rgb) \n",
    "\n",
    "    preds = classify_bboxes_with_clip(pil_img, bboxes)\n",
    "    annotated = img.copy()\n",
    "    for p in preds:\n",
    "      print('CLIP: ',p)\n",
    "      x, y, w, h = p[\"bbox\"]\n",
    "      label = f\"{p['label']} ({p['confidence']:.2f})\"\n",
    "      cv2.rectangle(annotated, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "      (tw, th), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "      cv2.rectangle(annotated, (x, y-th-4), (x+tw, y), (0, 255, 0), -1)\n",
    "      cv2.putText(annotated, label, (x, y-2), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    #annotated = results[0].plot(img = img.copy())  # built-in visualization\n",
    "\n",
    "    # Save output\n",
    "    cv2.imwrite(image_path + \"det_\"+ each_image, annotated)\n",
    "\n",
    "    print(f\"✅ Detection complete! Results saved det_{each_image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d2746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/openai/CLIP.git pillow torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac0d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip                # from OpenAI/CLIP repo\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# --- CONFIG ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"RN50\"   # clip models: \"ViT-B/32\", \"RN50\", etc.\n",
    "CLASS_NAMES = [\n",
    "    \"aphid\",\n",
    "    \"whitefly\",\n",
    "    \"thrips\",\n",
    "    \"spider mite\",\n",
    "    \"fungus gnat\",\n",
    "    \"leafhopper\",\n",
    "    \"beetle\"\n",
    "]\n",
    "TOP_K = 1                 # return top-k labels (set >1 if you want multiple)\n",
    "CONFIDENCE_THRESHOLD = 0.35  # below this -> \"unknown\" (tune for your data)\n",
    "\n",
    "# --- Load CLIP model & preprocessing ---\n",
    "model, preprocess = clip.load(MODEL_NAME, device=DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Create text prompts for each class (can be tuned)\n",
    "def build_prompts(class_names: List[str]) -> List[str]:\n",
    "    # small prompt engineering: be explicit it's an insect/pest\n",
    "    prompts = []\n",
    "    for c in class_names:\n",
    "        prompts.append(f\"a close up photo of a {c}\")\n",
    "        prompts.append(f\"a small insect identified as {c}\")\n",
    "    return prompts\n",
    "\n",
    "TEXT_PROMPTS = build_prompts(CLASS_NAMES)\n",
    "\n",
    "# Pre-encode text embeddings (we average prompt variants per class)\n",
    "with torch.no_grad():\n",
    "    text_tokens = clip.tokenize(TEXT_PROMPTS).to(DEVICE)\n",
    "    text_embeddings = model.encode_text(text_tokens)  # (N_prompts, D)\n",
    "    # normalize\n",
    "    text_embeddings = text_embeddings / text_embeddings.norm(dim=-1, keepdim=True)\n",
    "\n",
    "# Group embeddings per class by averaging variants\n",
    "def class_embeddings_from_prompt_embeddings(class_names: List[str],\n",
    "                                            text_embeddings: torch.Tensor) -> torch.Tensor:\n",
    "    # our build_prompts made 2 prompts per class in same order\n",
    "    per_class = []\n",
    "    prompts_per_class = len(TEXT_PROMPTS) // len(class_names)\n",
    "    for i in range(len(class_names)):\n",
    "        start = i * prompts_per_class\n",
    "        end = start + prompts_per_class\n",
    "        emb = text_embeddings[start:end].mean(dim=0)\n",
    "        emb = emb / emb.norm()  # re-normalize\n",
    "        per_class.append(emb)\n",
    "    return torch.stack(per_class, dim=0)  # (num_classes, D)\n",
    "\n",
    "CLASS_EMBEDDINGS = class_embeddings_from_prompt_embeddings(CLASS_NAMES, text_embeddings)\n",
    "\n",
    "# --- Helper: crop boxes and run CLIP ---\n",
    "def crop_from_bbox(pil_img: Image.Image, bbox: Tuple[int,int,int,int]) -> Image.Image:\n",
    "    \"\"\"\n",
    "    bbox expected as (x, y, w, h) in pixel coordinates.\n",
    "    Ensures bbox inside image, returns PIL crop.\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    # convert to left, upper, right, lower\n",
    "    left = max(int(x), 0)\n",
    "    upper = max(int(y), 0)\n",
    "    right = min(int(x + w), pil_img.width)\n",
    "    lower = min(int(y + h), pil_img.height)\n",
    "    if right <= left or lower <= upper:\n",
    "        # fallback: return full image if bbox degenerate\n",
    "        return pil_img.copy()\n",
    "    return pil_img.crop((left, upper, right, lower))\n",
    "\n",
    "def classify_bboxes_with_clip(\n",
    "    pil_img: Image.Image,\n",
    "    bboxes: List[Tuple[int,int,int,int]],\n",
    "    top_k: int = TOP_K,\n",
    "    threshold: float = CONFIDENCE_THRESHOLD\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      pil_img: PIL.Image of full image\n",
    "      bboxes: list of (x, y, w, h)\n",
    "    Returns:\n",
    "      list of dicts: {bbox, label, confidence, topk: [(label, score), ...]}\n",
    "    \"\"\"\n",
    "    crops = [crop_from_bbox(pil_img, bbox) for bbox in bboxes]\n",
    "    # Preprocess crops to CLIP input\n",
    "    inputs = torch.stack([preprocess(crop) for crop in crops], dim=0).to(DEVICE)  # (N, 3, H, W)\n",
    "    with torch.no_grad():\n",
    "        image_embeddings = model.encode_image(inputs)  # (N, D)\n",
    "        image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # similarity: cosine between image and class embeddings\n",
    "        # CLASS_EMBEDDINGS: (C, D)\n",
    "        # image_embeddings: (N, D)\n",
    "        sims = (image_embeddings @ CLASS_EMBEDDINGS.T)  # (N, C)\n",
    "        # Optionally scale by temperature if you want softmax; CLIP's default logit_scale:\n",
    "        logit_scale = model.logit_scale.exp().detach() if hasattr(model, \"logit_scale\") else 1.0\n",
    "        sims = sims * logit_scale\n",
    "\n",
    "        # Turn to probabilities with softmax for interpretability\n",
    "        probs = sims.softmax(dim=-1)  # (N, C)\n",
    "\n",
    "        results = []\n",
    "        for i in range(sims.shape[0]):\n",
    "            prob_row = probs[i].cpu().numpy()\n",
    "            # topk indices\n",
    "            topk_idx = np.argsort(prob_row)[::-1][:top_k]\n",
    "            topk = [(CLASS_NAMES[idx], float(prob_row[idx])) for idx in topk_idx]\n",
    "            # pick best\n",
    "            best_idx = int(topk_idx[0])\n",
    "            best_score = float(prob_row[best_idx])\n",
    "            label = CLASS_NAMES[best_idx] if best_score >= threshold else \"unknown\"\n",
    "            results.append({\n",
    "                \"bbox\": bboxes[i],\n",
    "                \"label\": label,\n",
    "                \"confidence\": best_score,\n",
    "                \"topk\": topk\n",
    "            })\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9676e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# If refined is still in OpenCV's BGR format, convert to RGB for matplotlib\n",
    "refined_rgb = cv2.cvtColor(refined, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(refined_rgb)\n",
    "plt.axis(\"off\")   # hides the axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e34f54eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 76.9ms\n",
      "Speed: 2.3ms preprocess, 76.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "✅ Detection complete! Results saved as flies_detected.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 3. Load YOLOv8 Model\n",
    "# ----------------------------\n",
    "model = YOLO(\"yolov8n.pt\")  # lightweight model for testing\n",
    "# You can swap for yolov8s.pt or yolov8m.pt for more accuracy\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Run Detection\n",
    "# ----------------------------\n",
    "results = model.predict(refined, imgsz=640, conf=0.25)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Draw bounding boxes & labels\n",
    "# ----------------------------\n",
    "annotated = results[0].plot()  # built-in visualization\n",
    "\n",
    "# Save output\n",
    "cv2.imwrite(\"flies_detected.jpg\", annotated)\n",
    "\n",
    "print(\"✅ Detection complete! Results saved as flies_detected.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d765908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show(\"flies_detected.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7ba1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
